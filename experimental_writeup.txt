For our tests, we tried to learn what parameters for minibatch size and learning rate performed the best in terms of both convergence speed and ultimately best validation error. We also wanted to see in what ways, if any, these parameter results varied depending on architecture, as well as which architecture performed best. The outcome of these results (best architecture with its best minibatch size and learning rate) would be used in our experiments with autoencoders to see how low we could push validation error.\\

The way that we performed these experiments was by testing every combination of minibatch size and learning rate (from a pre-picked set discussed earlier) with every architecture we thought feasible to try. We then compared these results and discovered that our architecture with 2 hidden layers (397 nodes and 203 nodes) performed the best out of our architectures. Also interestingly, each individual combination of minibatch size and learning rate performed roughly the same on every architecture, and the learning rate was clearly more important than the minibatch size in determining speed of convergence. Additionally, the combination of learning rate of 0.1 and minibatch size of 10 performed the best on every architecture. This was a bit surprising, because learning rates of 10^-3 showed up frequently in literature, and we were expecting the lower learning rates to perform better, but for this problem and our specified architectures, at least, this was not the case.\\
